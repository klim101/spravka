# timesheet_tab.py
# -*- coding: utf-8 -*-
"""
Streamlit-Ğ²ĞºĞ»Ğ°Ğ´ĞºĞ° Â«TimesheetÂ» Ğ´Ğ»Ñ Ğ²Ğ½ĞµÑĞµĞ½Ğ¸Ñ Ñ‡Ğ°ÑĞ¾Ğ² Ğ² Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ñƒ log.
ĞŸĞ¾Ñ…Ğ¾Ğ¶Ğµ Ğ½Ğ° nikatime.com: Ğ½ĞµĞ´ĞµĞ»ÑŒĞ½Ğ°Ñ ÑĞµÑ‚ĞºĞ° (ĞŸĞ½â€“Ğ’Ñ), ÑÑ‚Ñ€Ğ¾ĞºĞ¸ â€” Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ñ‹, ÑÑ‡ĞµĞ¹ĞºĞ¸ â€” Ñ‡Ğ°ÑÑ‹.
Ğ¥Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ â€” Ğ² PostgreSQL Supabase (Ğ²Ğ°Ğ¼ Ğ½Ğµ Ğ½ÑƒĞ¶Ğ½Ğ¾ Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ğ¾ ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ÑÑ‚ÑŒ PostgreSQL â€” ÑÑ‚Ğ¾ Ñ‚Ğ¾Ñ‚ Ğ¶Ğµ Ğ´Ğ²Ğ¸Ğ¶Ğ¾Ğº Ğ¿Ğ¾Ğ´ ĞºĞ°Ğ¿Ğ¾Ñ‚Ğ¾Ğ¼ Supabase).

Ğ—Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ (Ğ² requirements.txt):
    streamlit
    sqlalchemy
    psycopg2-binary
    pandas

Ğ¢Ñ€ĞµĞ±ÑƒĞµĞ¼Ñ‹Ğµ ÑĞµĞºÑ€ĞµÑ‚Ñ‹ (Streamlit â†’ Secrets):
    # Ğ²Ğ¾Ğ·ÑŒĞ¼Ğ¸Ñ‚Ğµ Ğ² Supabase: Project Settings â†’ Database â†’ Connection string â†’ SQLAlchemy
    POSTGRES_DSN = "postgresql+psycopg2://postgres:*****@db.<id>.supabase.co:5432/postgres"

ĞĞ¿Ñ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾:
    DEFAULT_TG_ID = 123456789  # ĞµÑĞ»Ğ¸ Ñ…Ğ¾Ñ‚Ğ¸Ñ‚Ğµ Ğ¿Ñ€ĞµĞ´Ğ²Ñ‹Ğ±Ğ¸Ñ€Ğ°Ñ‚ÑŒ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ Ğ¿Ğ¾ tg_id Ğ¿Ñ€Ğ¸ Ğ¿ĞµÑ€Ğ²Ğ¾Ğ¼ Ğ·Ğ°Ñ…Ğ¾Ğ´Ğµ
"""
from __future__ import annotations



import streamlit as st
from sqlalchemy.engine import URL


import socket
import psycopg2
from sqlalchemy import create_engine, text
from sqlalchemy.engine import URL

@st.cache_resource(show_spinner=False)
def get_engine():
    # 1) Ğ•ÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ñ‹Ğ¹ DSN Ğ² ÑĞµĞºÑ€ĞµÑ‚Ğ°Ñ…/Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ñ… â€” Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ ĞµĞ³Ğ¾ Ğ‘Ğ•Ğ— Ğ²Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚Ğ¾Ğ²
    dsn = (
        st.secrets.get("POSTGRES_DSN")
        or st.secrets.get("SUPABASE_DB_URL")
        or os.getenv("DATABASE_URL")
    )
    if dsn:
        eng = create_engine(dsn, pool_pre_ping=True, pool_recycle=1800, future=True)
        # ĞĞµĞ±Ğ¾Ğ»ÑŒÑˆĞ°Ñ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ¸ Ğ¿Ğ¾Ğ´ÑĞºĞ°Ğ·ĞºĞ°, ĞºĞ°ĞºĞ¸Ğ¼ Ğ´Ñ€Ğ°Ğ¹Ğ²ĞµÑ€Ğ¾Ğ¼ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾ Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡Ğ¸Ğ»Ğ¸ÑÑŒ
        try:
            with eng.connect() as c:
                c.exec_driver_sql("SELECT 1")
            st.caption(f"DB OK Â· {eng.dialect.name}+{eng.dialect.driver}")
        except Exception as e:
            st.error(f"ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡Ğ¸Ñ‚ÑŒÑÑ Ğ¿Ğ¾ POSTGRES_DSN: {e}")
            st.stop()
        return eng

    # 2) Ğ—Ğ°Ğ¿Ğ°ÑĞ½Ğ¾Ğ¹ Ğ¿ÑƒÑ‚ÑŒ (ĞµÑĞ»Ğ¸ Ğ²Ğ´Ñ€ÑƒĞ³ DSN Ğ½Ğµ Ğ´Ğ°Ğ»Ğ¸): ÑĞ¾Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ URL Ğ¿Ğ¾Ğ´ pg8000 Ñ SSL
    host = st.secrets["SUPA_HOST"]
    user = st.secrets.get("SUPA_USER", "postgres")
    pwd  = st.secrets["SUPA_PASSWORD"]
    db   = st.secrets.get("SUPA_DB", "postgres")

    url = URL.create(
        "postgresql+pg8000",
        username=user,
        password=pwd,
        host=host,
        port=5432,
        database=db,
        query={"ssl": "true"},
    )
    eng = create_engine(url, pool_pre_ping=True, pool_recycle=1800, future=True)
    with eng.connect() as c:
        c.exec_driver_sql("SELECT 1")
    st.caption(f"DB OK Â· {eng.dialect.name}+{eng.dialect.driver}")
    return eng




import os
from dataclasses import dataclass
from datetime import date, datetime, timedelta
from typing import List, Dict, Tuple, Optional

import pandas as pd
import streamlit as st
from sqlalchemy import create_engine, text, inspect

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# DB utilities
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

from urllib.parse import urlsplit, urlunsplit, parse_qsl, urlencode

def _dsn_from_secrets() -> str:
    import os, streamlit as st

    dsn = (
        st.secrets.get("POSTGRES_DSN")
        or st.secrets.get("SUPABASE_DB_URL")
        or os.getenv("DATABASE_URL")
    )
    if not dsn:
        raise RuntimeError("ĞĞµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½ DSN Ğº PostgreSQL Supabase. Ğ”Ğ¾Ğ±Ğ°Ğ²ÑŒÑ‚Ğµ POSTGRES_DSN (Ğ¸Ğ»Ğ¸ SUPABASE_DB_URL) Ğ² st.secrets.")

    # ĞĞ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·ÑƒĞµĞ¼ Ğ¿Ñ€ĞµÑ„Ğ¸ĞºÑ:
    dsn = dsn.replace("postgres://", "postgresql://", 1)

    # Ğ’ÑĞµĞ³Ğ´Ğ° Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ pg8000 + SSL
    if dsn.startswith("postgresql://"):
        dsn = dsn.replace("postgresql://", "postgresql+pg8000://", 1)
    if ("sslmode=" not in dsn) and ("ssl=" not in dsn):
        dsn += ("&" if "?" in dsn else "?") + "ssl=true"

    return dsn




@st.cache_resource(show_spinner=False)
def get_engine():
    dsn = _dsn_from_secrets()
    eng = create_engine(dsn, pool_pre_ping=True, pool_recycle=1800)
    return eng


def _detect_user_table(engine) -> str:
    """
    Ğ’ Ğ½ĞµĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ñ… Ğ‘Ğ” Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ğ° Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¹ Ğ½Ğ°Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ÑÑ 'user' (Ğ·Ğ°Ñ€ĞµĞ·ĞµÑ€Ğ². ÑĞ»Ğ¾Ğ²Ğ¾ Ğ² SQL),
    Ñƒ Ğ²Ğ°Ñ â€” Ğ²ĞµÑ€Ğ¾ÑÑ‚Ğ½Ğ¾ 'klim101'. ĞĞ¿Ñ€ĞµĞ´ĞµĞ»Ğ¸Ğ¼ ĞºĞ¾Ñ€Ñ€ĞµĞºÑ‚Ğ½Ğ¾Ğµ Ğ¸Ğ¼Ñ.
    """
    insp = inspect(engine)
    names = {t.lower() for t in insp.get_table_names()}
    if "klim101" in names:
        return "klim101"
    if "user" in names:
        return '"user"'  # ÑĞºÑ€Ğ°Ğ½Ğ¸Ñ€ÑƒĞµĞ¼ Ğ·Ğ°Ñ€ĞµĞ·ĞµÑ€Ğ²Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğµ ÑĞ»Ğ¾Ğ²Ğ¾
    # Ğ½Ğ° ĞºÑ€Ğ°Ğ¹Ğ½Ğ¸Ğ¹ ÑĞ»ÑƒÑ‡Ğ°Ğ¹ ÑĞ¾Ğ·Ğ´Ğ°Ğ´Ğ¸Ğ¼ 'klim101'
    return "klim101"


def ensure_db():
    """
    Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ñ‚ Ğ½ĞµĞ´Ğ¾ÑÑ‚Ğ°ÑÑ‰Ğ¸Ğµ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ñ‹/Ğ¸Ğ½Ğ´ĞµĞºÑÑ‹. Ğ‘ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ğ¾ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ÑÑ‚ÑŒ Ğ¿Ñ€Ğ¸ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ¼ ÑÑ‚Ğ°Ñ€Ñ‚Ğµ.
    ĞĞ¸Ñ‡ĞµĞ³Ğ¾ Ğ½Ğµ Ñ‚Ñ€Ñ‘Ñ‚.
    """
    eng = get_engine()
    user_tbl = _detect_user_table(eng)

    ddl_user = f"""
    CREATE TABLE IF NOT EXISTS {user_tbl} (
        id         BIGINT PRIMARY KEY,
        tg_id      BIGINT NOT NULL,
        first_name VARCHAR NOT NULL
    );
    """

    ddl_project = """
    CREATE TABLE IF NOT EXISTS project (
        id   BIGINT PRIMARY KEY,
        name VARCHAR NOT NULL UNIQUE
    );
    """

    ddl_log = f"""
    CREATE TABLE IF NOT EXISTS log (
        id         BIGINT PRIMARY KEY,
        user_id    BIGINT NOT NULL REFERENCES {user_tbl} (id),
        project_id BIGINT NOT NULL REFERENCES project (id),
        work_date  DATE    NOT NULL,
        hours      FLOAT   NOT NULL
    );
    """

    # Ğ˜Ğ½Ğ´ĞµĞºÑ Ğ´Ğ»Ñ Ğ±Ñ‹ÑÑ‚Ñ€Ñ‹Ñ… Ğ°Ğ¿Ğ´ĞµĞ¹Ñ‚Ğ¾Ğ²/Ğ²ÑÑ‚Ğ°Ğ²Ğ¾Ğº Ğ¿Ğ¾ ĞºĞ»ÑÑ‡Ñƒ (user, project, date)
    ddl_uniq = """
    DO $$
    BEGIN
        IF NOT EXISTS (
            SELECT 1 FROM pg_indexes WHERE indexname = 'ux_log_user_project_date'
        ) THEN
            CREATE UNIQUE INDEX ux_log_user_project_date
            ON log (user_id, project_id, work_date);
        END IF;
    END $$;
    """

    with eng.begin() as con:
        con.execute(text(ddl_user))
        con.execute(text(ddl_project))
        con.execute(text(ddl_log))
        # Ğ¿Ğ¾Ğ¿Ñ‹Ñ‚ĞºĞ° ÑĞ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ uniq Ğ¸Ğ½Ğ´ĞµĞºÑ; ĞµÑĞ»Ğ¸ ÑƒĞ¶Ğµ ĞµÑÑ‚ÑŒ â€” Ğ¸Ğ³Ğ½Ğ¾Ñ€Ğ¸Ñ€ÑƒĞµĞ¼
        try:
            con.execute(text(ddl_uniq))
        except Exception:
            pass


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Query helpers
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@dataclass
class TimesheetWeek:
    monday: date
    dates: List[date]  # 7 Ğ´Ğ°Ñ‚ ĞŸĞ½â€“Ğ’Ñ

    @staticmethod
    def from_any(d: date | datetime | None = None) -> "TimesheetWeek":
        if d is None:
            d = date.today()
        d = d.date() if isinstance(d, datetime) else d
        monday = d - timedelta(days=(d.weekday() % 7))  # Monday=0
        return TimesheetWeek(monday=monday, dates=[monday + timedelta(days=i) for i in range(7)])


@st.cache_data(ttl=60, show_spinner=False)
def fetch_projects() -> pd.DataFrame:
    eng = get_engine()
    q = text("SELECT id, name FROM project ORDER BY name")
    return pd.read_sql(q, eng)


@st.cache_data(ttl=60, show_spinner=False)
def fetch_users() -> pd.DataFrame:
    eng = get_engine()
    user_tbl = _detect_user_table(eng)
    q = text(f"SELECT id, first_name, tg_id FROM {user_tbl} ORDER BY first_name")
    return pd.read_sql(q, eng)


def fetch_week_hours(user_id: int, week: TimesheetWeek) -> pd.DataFrame:
    eng = get_engine()
    q = text("""
        SELECT project_id, work_date, SUM(hours) AS hours
        FROM log
        WHERE user_id = :uid AND work_date BETWEEN :d1 AND :d7
        GROUP BY project_id, work_date
    """)
    df = pd.read_sql(q, eng, params={"uid": user_id, "d1": week.dates[0], "d7": week.dates[-1]})
    return df


def _next_log_ids(con, n: int) -> List[int]:
    cur = con.execute(text("SELECT COALESCE(MAX(id), 0) FROM log"))
    start = int(cur.scalar() or 0) + 1
    return list(range(start, start + n))


def upsert_week(payload_rows: List[Dict], user_id: int, week: TimesheetWeek) -> None:
    """
    payload_rows: ÑĞ¿Ğ¸ÑĞ¾Ğº ÑÑ‚Ñ€Ğ¾Ğº Ğ²Ğ¸Ğ´Ğ°:
        {'project_id': int, 'hours': {date: float, ...}}
    ĞŸÑ€Ğ°Ğ²Ğ¸Ğ»Ğ¾: Ğ´Ğ»Ñ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ¹ Ğ¿Ğ°Ñ€Ñ‹ (user_id, project_id, work_date) Ğ¿Ğ¾Ğ»Ğ½Ğ¾ÑÑ‚ÑŒÑ ĞŸĞ•Ğ Ğ•Ğ—ĞĞŸĞ˜Ğ¡Ğ«Ğ’ĞĞ•Ğœ Ñ‡Ğ°ÑÑ‹:
    â€” ĞµÑĞ»Ğ¸ Ğ½Ğ¾Ğ²Ğ°Ñ ÑÑ‡ĞµĞ¹ĞºĞ° > 0: UPSERT
    â€” ĞµÑĞ»Ğ¸ 0 Ğ¸Ğ»Ğ¸ NaN: DELETE
    """
    eng = get_engine()
    with eng.begin() as con:
        to_insert: List[Tuple[int,int,int,date,float]] = []
        to_delete: List[Tuple[int,int,date]] = []
        for row in payload_rows:
            pid = int(row["project_id"])
            hours_map: Dict[date, float] = row.get("hours", {})
            for d in week.dates:
                v = hours_map.get(d, 0.0)
                try:
                    h = float(v) if v is not None and str(v).strip() != "" else 0.0
                except Exception:
                    h = 0.0
                if h > 0:
                    to_insert.append((0, user_id, pid, d, h))
                else:
                    to_delete.append((user_id, pid, d))

        if to_delete:
            con.execute(
                text("""
                    DELETE FROM log
                    WHERE (user_id, project_id, work_date) IN (
                        SELECT * FROM UNNEST(:uids::bigint[], :pids::bigint[], :dates::date[])
                    )
                """),
                params={
                    "uids":  [u for (u, _, _) in to_delete],
                    "pids":  [p for (_, p, _) in to_delete],
                    "dates": [d for (_, _, d) in to_delete],
                },
            )

        if to_insert:
            ids = _next_log_ids(con, len(to_insert))
            uids  = [u for (_, u, _, _, _) in to_insert]
            pids  = [p for (_, _, p, _, _) in to_insert]
            dates = [d for (_, _, _, d, _) in to_insert]
            hrs   = [h for (_, _, _, _, h) in to_insert]

            try:
                con.execute(
                    text("""
                        INSERT INTO log (id, user_id, project_id, work_date, hours)
                        SELECT * FROM UNNEST(:ids::bigint[], :uids::bigint[], :pids::bigint[], :dates::date[], :hrs::float[])
                        ON CONFLICT (user_id, project_id, work_date) DO UPDATE
                        SET hours = EXCLUDED.hours;
                    """),
                    params={"ids": ids, "uids": uids, "pids": pids, "dates": dates, "hrs": hrs},
                )
            except Exception:
                con.execute(
                    text("""
                        DELETE FROM log
                        WHERE (user_id, project_id, work_date) IN (
                            SELECT * FROM UNNEST(:uids::bigint[], :pids::bigint[], :dates::date[])
                        )
                    """),
                    params={"uids": uids, "pids": pids, "dates": dates},
                )
                con.execute(
                    text("""
                        INSERT INTO log (id, user_id, project_id, work_date, hours)
                        SELECT * FROM UNNEST(:ids::bigint[], :uids::bigint[], :pids::bigint[], :dates::date[], :hrs::float[])
                    """),
                    params={"ids": ids, "uids": uids, "pids": pids, "dates": dates, "hrs": hrs},
                )


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# UI helpers
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

_CSS = """
<style>
.block-container {padding-top: 1.2rem; max-width: 1100px;}
h1, h2, h3 {font-weight: 700;}
.ts-grid {border-collapse: separate; border-spacing: 0; width: 100%;}
.ts-grid th {position: sticky; top: 0; background: #fff; z-index: 2;}
.ts-grid th, .ts-grid td {border-bottom: 1px solid #e8e8e8; padding: 8px 10px;}
.ts-grid thead tr {border-bottom: 2px solid #dcdcdc;}
.ts-grid .muted {color: #888;}
.ts-total {text-align: right; font-weight: 700;}
.ts-controls {display:flex; flex-wrap: wrap; gap: 10px; align-items: center;}
.ts-controls > * {flex: 0 0 auto;}
.stDataFrame {border: 1px solid #eee; border-radius: 12px;}
.small {font-size: 12px; color:#666;}
</style>
"""


def _day_cols(week: TimesheetWeek) -> List[str]:
    ru = ["ĞŸĞ½", "Ğ’Ñ‚", "Ğ¡Ñ€", "Ğ§Ñ‚", "ĞŸÑ‚", "Ğ¡Ğ±", "Ğ’Ñ"]
    return [f"{ru[i]} {d.strftime('%d.%m')}" for i, d in enumerate(week.dates)]


def _empty_df(projects: pd.DataFrame, week: TimesheetWeek) -> pd.DataFrame:
    cols = ["ĞŸÑ€Ğ¾ĞµĞºÑ‚"] + _day_cols(week) + ["Ğ˜Ñ‚Ğ¾Ğ³Ğ¾"]
    df = pd.DataFrame(columns=cols)
    return df


def _prefill_df(user_id: int, week: TimesheetWeek, projects: pd.DataFrame) -> pd.DataFrame:
    day_cols = _day_cols(week)
    df = _empty_df(projects, week)
    raw = fetch_week_hours(user_id, week)
    if raw.empty:
        return df
    pid2name = dict(projects[["id", "name"]].values)
    rows: Dict[int, Dict[str, float]] = {}
    for _, r in raw.iterrows():
        pid = int(r["project_id"])
        wd  = pd.to_datetime(r["work_date"]).date()
        h   = float(r["hours"] or 0.0)
        label = pid2name.get(pid, f"#{pid}")
        rows.setdefault(pid, {"ĞŸÑ€Ğ¾ĞµĞºÑ‚": label, **{c: 0.0 for c in day_cols}})
        for i, d in enumerate(week.dates):
            if d == wd:
                rows[pid][day_cols[i]] = h
                break
    if not rows:
        return df
    df = pd.DataFrame(list(rows.values()))
    df["Ğ˜Ñ‚Ğ¾Ğ³Ğ¾"] = df[day_cols].sum(axis=1)
    df = df.sort_values("ĞŸÑ€Ğ¾ĞµĞºÑ‚").reset_index(drop=True)
    return df


def _as_payload(edited: pd.DataFrame, projects: pd.DataFrame, week: TimesheetWeek) -> List[Dict]:
    name2pid = {n: int(i) for i, n in projects[["id", "name"]].values}
    day_cols = _day_cols(week)
    out: List[Dict] = []
    for _, row in edited.iterrows():
        pname = str(row.get("ĞŸÑ€Ğ¾ĞµĞºÑ‚") or "").strip()
        if not pname:
            continue
        pid = name2pid.get(pname)
        if not pid:
            continue
        hours_map: Dict[date, float] = {}
        for i, col in enumerate(day_cols):
            v = row.get(col, 0.0)
            try:
                h = float(v) if v is not None and str(v).strip() != "" else 0.0
            except Exception:
                h = 0.0
            hours_map[week.dates[i]] = h
        out.append({"project_id": pid, "hours": hours_map})
    return out


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Persisting chosen user (select once)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _get_saved_uid() -> Optional[int]:
    # 1) query params
    try:
        qp = st.experimental_get_query_params()  # ÑĞ¾Ğ²Ğ¼ĞµÑÑ‚Ğ¸Ğ¼Ğ¾ÑÑ‚ÑŒ Ñ Ñ€Ğ°Ğ·Ğ½Ñ‹Ğ¼Ğ¸ Ğ²ĞµÑ€ÑĞ¸ÑĞ¼Ğ¸ Streamlit
        uid = qp.get("uid", [None])[0]
    except Exception:
        uid = None
    if uid:
        try:
            return int(uid)
        except Exception:
            return None
    # 2) session_state
    if "uid" in st.session_state:
        try:
            return int(st.session_state["uid"])
        except Exception:
            pass
    return None


def _save_uid(uid: int) -> None:
    st.session_state["uid"] = int(uid)
    try:
        st.experimental_set_query_params(uid=str(uid))
    except Exception:
        pass


def _clear_saved_uid() -> None:
    st.session_state.pop("uid", None)
    try:
        st.experimental_set_query_params()  # Ğ¾Ñ‡Ğ¸ÑÑ‚Ğ¸Ñ‚ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹
    except Exception:
        pass


def _header_controls(users: pd.DataFrame, projects: pd.DataFrame) -> Tuple[int, TimesheetWeek, List[str]]:
    st.markdown(_CSS, unsafe_allow_html=True)
    st.subheader("â±ï¸ Timesheet")

    col1, col2, col3 = st.columns([1.1, 1.4, 2])
    with col1:
        picked = st.date_input("ĞĞµĞ´ĞµĞ»Ñ", value=date.today(), format="DD.MM.YYYY")
        week = TimesheetWeek.from_any(picked)

    # Ğ’Ñ‹Ğ±Ğ¾Ñ€/Ñ„Ğ¸ĞºÑĞ°Ñ†Ğ¸Ñ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ: "Ğ²Ñ‹Ğ±ĞµÑ€Ğ¸ Ğ¾Ğ´Ğ¸Ğ½ Ñ€Ğ°Ğ· Ğ¸ Ğ±Ğ¾Ğ»ÑŒÑˆĞµ Ğ½Ğµ ÑĞ¿Ñ€Ğ°ÑˆĞ¸Ğ²Ğ°ĞµĞ¼"
    saved_uid = _get_saved_uid()
    user_id: Optional[int] = None

    valid_ids = set(users["id"].astype(int).tolist())

    with col2:
        if saved_uid and int(saved_uid) in valid_ids:
            # ĞĞ°Ğ¹Ğ´Ñ‘Ğ¼ Ğ¸Ğ¼Ñ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ
            row = users[users["id"] == int(saved_uid)].iloc[0]
            st.markdown(f"**ĞŸĞ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒ:** {row['first_name']}  Â·  id={int(row['id'])}")
            if st.button("Ğ¡Ğ¼ĞµĞ½Ğ¸Ñ‚ÑŒ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ"):
                _clear_saved_uid()
                st.experimental_rerun()
            user_id = int(saved_uid)
        else:
            # ĞŸĞµÑ€Ğ²Ñ‹Ğ¹ Ğ·Ğ°Ñ…Ğ¾Ğ´: Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ Ğ²Ñ‹Ğ±Ğ¾Ñ€ Ğ¾Ğ´Ğ¸Ğ½ Ñ€Ğ°Ğ·
            # ĞŸÑ€ĞµĞ´Ğ²Ñ‹Ğ±Ğ¾Ñ€ Ğ¿Ğ¾ DEFAULT_TG_ID (ĞµÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ)
            default_idx = 0
            default_tg = st.secrets.get("DEFAULT_TG_ID")
            if default_tg:
                try:
                    default_idx = users.index[users["tg_id"] == int(default_tg)][0]
                except Exception:
                    default_idx = 0

            ulabel = st.selectbox(
                "Ğ’Ñ‹Ğ±ĞµÑ€Ğ¸Ñ‚Ğµ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ (Ğ¾Ğ´Ğ¸Ğ½ Ñ€Ğ°Ğ·)",
                options=list(users["first_name"] + "  Â·  id=" + users["id"].astype(str)),
                index=default_idx,
            )
            user_id = int(ulabel.split("id=")[-1])
            # Ñ„Ğ¸ĞºÑĞ¸Ñ€ÑƒĞµĞ¼ Ğ²Ñ‹Ğ±Ğ¾Ñ€, Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Ğ±Ğ¾Ğ»ÑŒÑˆĞµ Ğ½Ğµ ÑĞ¿Ñ€Ğ°ÑˆĞ¸Ğ²Ğ°Ñ‚ÑŒ
            _save_uid(user_id)

    with col3:
        st.markdown(
            f"""
            <div class="small">ĞĞµĞ´ĞµĞ»Ñ: <b>{week.dates[0].strftime('%d.%m.%Y')}</b> â€” <b>{week.dates[-1].strftime('%d.%m.%Y')}</b><br>
            Ğ’Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ Ñ‡Ğ°ÑÑ‹ Ğ² ÑÑ‡ĞµĞ¹ĞºĞ¸. 0 Ğ¸Ğ»Ğ¸ Ğ¿ÑƒÑÑ‚Ğ¾ â€” ÑƒĞ´Ğ°Ğ»ĞµĞ½Ğ¸Ğµ Ğ·Ğ°Ğ¿Ğ¸ÑĞ¸. ĞĞ°Ğ¶Ğ¼Ğ¸Ñ‚Ğµ Â«Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½Ğ¸Ñ‚ÑŒÂ».</div>
            """,
            unsafe_allow_html=True,
        )

    days = _day_cols(week)
    return user_id, week, days


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Main UI
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def render_timesheet_tab():
    """ĞÑĞ½Ğ¾Ğ²Ğ½Ğ°Ñ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ²ĞºĞ»Ğ°Ğ´ĞºĞ¸ Timesheet. Ğ’Ñ‹Ğ·Ñ‹Ğ²Ğ°Ğ¹Ñ‚Ğµ Ğ¸Ğ· Ğ²Ğ°ÑˆĞµĞ³Ğ¾ Ğ³Ğ»Ğ°Ğ²Ğ½Ğ¾Ğ³Ğ¾ Ñ„Ğ°Ğ¹Ğ»Ğ°."""
    ensure_db()  # Ğ±ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ğ¾
    projects = fetch_projects()
    users = fetch_users()

    if projects.empty or users.empty:
        st.info("Ğ”Ğ¾Ğ±Ğ°Ğ²ÑŒÑ‚Ğµ Ñ…Ğ¾Ñ‚Ñ Ğ±Ñ‹ Ğ¾Ğ´Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ Ğ¸ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚ Ğ² Ğ‘Ğ”, Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Ğ½Ğ°Ñ‡Ğ°Ñ‚ÑŒ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñƒ.")
        st.stop()

    user_id, week, day_cols = _header_controls(users, projects)

    # ĞšĞ½Ğ¾Ğ¿ĞºĞ¸ Ğ±Ñ‹ÑÑ‚Ñ€Ğ¾Ğ³Ğ¾ Ğ·Ğ°Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ñ
    cc1, cc2, cc3, cc4 = st.columns([1, 1, 1, 4])
    with cc1:
        if st.button("Ğ—Ğ°Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ÑŒ 8Ñ‡ Ğ¿Ğ¾ Ğ±ÑƒĞ´Ğ½ÑĞ¼", use_container_width=True):
            st.session_state.setdefault("ts_quick_fill", {})[user_id] = {d: (8.0 if i < 5 else 0.0) for i, d in enumerate(week.dates)}
    with cc2:
        if st.button("ĞÑ‡Ğ¸ÑÑ‚Ğ¸Ñ‚ÑŒ Ğ½ĞµĞ´ĞµĞ»Ñ", use_container_width=True):
            st.session_state.setdefault("ts_quick_fill", {})[user_id] = {d: 0.0 for d in week.dates}
    with cc3:
        if st.button("Ğ¡ĞºĞ¾Ğ¿Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ñ Ğ¿Ñ€Ğ¾ÑˆĞ»Ğ¾Ğ¹ Ğ½ĞµĞ´ĞµĞ»Ğ¸", use_container_width=True):
            prev = TimesheetWeek(week.monday - timedelta(days=7), [week.monday - timedelta(days=7) + timedelta(days=i) for i in range(7)])
            prev_df = fetch_week_hours(user_id, prev)
            st.session_state.setdefault("ts_paste_prev", {})[user_id] = prev_df

    base_df = _prefill_df(user_id, week, projects)

    quick = st.session_state.get("ts_quick_fill", {}).get(user_id)
    paste_prev = st.session_state.get("ts_paste_prev", {}).get(user_id)

    if paste_prev is not None and not paste_prev.empty:
        pid2name = dict(projects[["id", "name"]].values)
        proj_ids = sorted(paste_prev["project_id"].unique().tolist())
        df = pd.DataFrame({"ĞŸÑ€Ğ¾ĞµĞºÑ‚": [pid2name.get(pid, f"#{pid}") for pid in proj_ids]})
        for i, d in enumerate(week.dates):
            col = day_cols[i]
            prev_day = d - timedelta(days=7)
            merged = paste_prev[paste_prev["work_date"] == pd.to_datetime(prev_day)]
            hours_by_pid = merged.set_index("project_id")["hours"].to_dict()
            df[col] = [float(hours_by_pid.get(pid, 0.0)) for pid in proj_ids]
        df["Ğ˜Ñ‚Ğ¾Ğ³Ğ¾"] = df[day_cols].sum(axis=1)
        base_df = df

    if quick is not None:
        for i, d in enumerate(week.dates):
            base_df[day_cols[i]] = float(quick.get(d, 0.0))
        base_df["Ğ˜Ñ‚Ğ¾Ğ³Ğ¾"] = base_df[day_cols].sum(axis=1)

    st.markdown("<hr>", unsafe_allow_html=True)

    edited = st.data_editor(
        base_df,
        use_container_width=True,
        hide_index=True,
        column_config={},
        num_rows="dynamic",
        key=f"ts_editor_{user_id}_{week.monday.isoformat()}",
    )
    try:
        edited["Ğ˜Ñ‚Ğ¾Ğ³Ğ¾"] = edited[day_cols].apply(pd.to_numeric, errors="coerce").fillna(0.0).sum(axis=1)
    except Exception:
        edited["Ğ˜Ñ‚Ğ¾Ğ³Ğ¾"] = 0.0

    st.markdown("<br>", unsafe_allow_html=True)
    c1, c2 = st.columns([1, 4])
    with c1:
        if st.button("ğŸ’¾ Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½Ğ¸Ñ‚ÑŒ", type="primary", use_container_width=True):
            known_names = set(projects["name"].tolist())
            bad = [str(x) for x in edited["ĞŸÑ€Ğ¾ĞµĞºÑ‚"].tolist() if str(x) not in known_names]
            if bad:
                st.error("Ğ­Ñ‚Ğ¸ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ñ‹ Ğ¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ğ²ÑƒÑÑ‚ Ğ² ÑĞ¿Ñ€Ğ°Ğ²Ğ¾Ñ‡Ğ½Ğ¸ĞºĞµ: " + ", ".join(bad))
            else:
                payload = _as_payload(edited, projects, week)
                try:
                    upsert_week(payload, user_id, week)
                    st.success("Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¾ âœ”")
                    fetch_week_hours.clear()
                    fetch_projects.clear()
                except Exception as e:
                    st.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ñ: {e}")
    with c2:
        st.markdown(
            "<span class='small'>ĞŸĞ¾Ğ´ÑĞºĞ°Ğ·ĞºĞ°: Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ÑÑ‚ÑŒ/Ğ¿ĞµÑ€ĞµĞ¸Ğ¼ĞµĞ½Ğ¾Ğ²Ñ‹Ğ²Ğ°Ñ‚ÑŒ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ñ‹ Ğ¸ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¹ Ğ»ÑƒÑ‡ÑˆĞµ Ñ‡ĞµÑ€ĞµĞ· SQL Ğ¸Ğ»Ğ¸ Ğ²Ğ°ÑˆÑƒ Ğ°Ğ´Ğ¼Ğ¸Ğ½ĞºÑƒ. "
            "Ğ­Ñ‚Ğ° Ğ²ĞºĞ»Ğ°Ğ´ĞºĞ° Ñ€ĞµĞ´Ğ°ĞºÑ‚Ğ¸Ñ€ÑƒĞµÑ‚ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ñ‡Ğ°ÑÑ‹ Ğ² log. Ğ§Ñ‚Ğ¾Ğ±Ñ‹ ÑĞ¼ĞµĞ½Ğ¸Ñ‚ÑŒ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ â€” Ğ½Ğ°Ğ¶Ğ¼Ğ¸Ñ‚Ğµ Â«Ğ¡Ğ¼ĞµĞ½Ğ¸Ñ‚ÑŒ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑÂ».</span>",
            unsafe_allow_html=True,
        )

    total_week = float(edited["Ğ˜Ñ‚Ğ¾Ğ³Ğ¾"].sum()) if not edited.empty else 0.0
    st.markdown(f"**Ğ˜Ñ‚Ğ¾Ğ³Ğ¾ Ğ·Ğ° Ğ½ĞµĞ´ĞµĞ»Ñ:** {total_week:.2f} Ñ‡")










